{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv('LA_Airbnb/listings_detailed.csv')\n",
    "listings['clean_price'] = [float(i.replace('$','').replace(',','')) for i in listings['price']]\n",
    "room_codes = [i.split('/')[-1] for i in listings['listing_url'].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_paths = []\n",
    "# all_labels = []\n",
    "# for room_code in tqdm(room_codes):\n",
    "#     try: \n",
    "#         photos = os.listdir(f'LA_photos/{room_code}')\n",
    "#     except: \n",
    "#         continue\n",
    "#     all_paths.extend([f'LA_photos/{room_code}/{i}' for i in photos])\n",
    "#     labels = listings.set_index('id').clean_price.loc[float(room_code)]\n",
    "#     if not isinstance(labels, float):\n",
    "#         raise\n",
    "#     all_labels.append([labels for count in range(len(photos))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_room_codes = np.random.choice(room_codes,size=int(len(room_codes)*0.90),replace=False)\n",
    "testing_room_codes = [i for i in room_codes if not i in training_room_codes]\n",
    "training_labels = listings.set_index('id').clean_price.loc[[float(i) for i in training_room_codes]].values\n",
    "testing_labels = listings.set_index('id').clean_price.loc[[float(i) for i in testing_room_codes]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36394, 4044)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_room_codes),len(testing_room_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_utiles import train_loader,SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "device = torch.device(\"mps\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class early_stopper():\n",
    "    def __init__(self,patient = 3):\n",
    "        self.val_loss_list = []\n",
    "        self.train_loss_list = []\n",
    "        self.lowest_val_loss = 1e8\n",
    "        self.patient = patient\n",
    "    def check_early_stopping_store_best(self,model,val_loss,train_loss):\n",
    "        self.train_loss_list.append(train_loss)\n",
    "        if len(self.val_loss_list)<self.patient:\n",
    "            self.val_loss_list.append(val_loss)\n",
    "            if val_loss<self.lowest_val_loss:\n",
    "                self.lowest_val_loss = val_loss\n",
    "                pickle.dump(model.to('cpu'), open('best_CNN.pkl','wb'))\n",
    "        else:\n",
    "            if val_loss>np.max(self.val_loss_list[-self.patient:]):\n",
    "                return True\n",
    "            else:\n",
    "                if val_loss<self.lowest_val_loss:\n",
    "                    self.lowest_val_loss = val_loss\n",
    "                    pickle.dump(model.to('cpu'), open('best_CNN.pkl','wb'))\n",
    "                return False\n",
    "\n",
    "stopper = early_stopper(patient=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [07:23<?, ?it/s, epoch 0, batch loss:0.5318026542663574, last training loss: nan, last validation loss: nan] /Users/chenyangkang/miniforge3/lib/python3.9/site-packages/PIL/JpegImagePlugin.py:835: UserWarning: Image appears to be a malformed MPO file, it will be interpreted as a base JPEG file\n",
      "  warnings.warn(\n",
      "100%|██████████| 20/20 [14:29:10<00:00, 2607.54s/it, epoch 19, training loss: 0.5866107593484337, validation loss: 0.6225075721740723]                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_pogress = tqdm(range(20))\n",
    "mean_training_loss = np.nan\n",
    "mean_val_loss = np.nan\n",
    "\n",
    "\n",
    "for epoch in epoch_pogress:  # loop over the dataset multiple times\n",
    "\n",
    "    ### training\n",
    "    tr_loader = train_loader(training_room_codes,training_labels, batch_size=50) ### reset data each epoch\n",
    "\n",
    "    loss_list = []\n",
    "    for i, data in enumerate(tr_loader.generate_dataset()):\n",
    "        model.train()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels, frac_rooms_trained = data\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        score = loss.item()\n",
    "        loss_list.append(loss.item())\n",
    "        epoch_pogress.set_postfix_str(f\"epoch {epoch}, batch loss:{score}, last training loss: {mean_training_loss}, last validation loss: {mean_val_loss}\") \n",
    "\n",
    "    mean_training_loss = np.mean(loss_list)\n",
    "\n",
    "    ### validation\n",
    "    val_loader = train_loader(testing_room_codes,testing_labels, batch_size=50) ### regenerate val set each time\n",
    "\n",
    "    ##\n",
    "    loss_list = []\n",
    "    for val_index, data in enumerate(val_loader.generate_dataset()):\n",
    "        model.eval()\n",
    "        inputs, labels, frac_rooms_tested = data\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "\n",
    "        pred = model(inputs)\n",
    "        loss_val = criterion(pred, labels)\n",
    "        loss_list.append(loss.item())\n",
    "    \n",
    "    mean_val_loss = np.mean(loss_list)\n",
    "    stop = stopper.check_early_stopping_store_best(model, mean_val_loss, mean_training_loss)\n",
    "    model = model.to(device)\n",
    "    scheduler.step(mean_val_loss)\n",
    "    epoch_pogress.set_postfix_str(f\"epoch {epoch}, training loss: {mean_training_loss}, validation loss: {mean_val_loss}\") \n",
    "    if stop:\n",
    "        break\n",
    "            \n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e9867b585c0f10e2eb480253e40cab44b53d9f15cdd7fb9c79b17a5cb2fa039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
