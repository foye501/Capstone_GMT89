{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ner(sentence, spacy_pipeline):\n",
    "    # Process the input text with the NER component\n",
    "    if sentence:\n",
    "        doc = spacy_pipeline(sentence)\n",
    "        LOCs = []\n",
    "        # Print the named entities and their labels\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in [\"FAC\",\"LOC\",\"ORG\"]:\n",
    "                # print(ent.text)\n",
    "                LOCs.append(ent.text)\n",
    "        return LOCs\n",
    "\n",
    "import re\n",
    "# there are some block need to be removed.\n",
    "def replace_br(locs):\n",
    "    newlocs=[]\n",
    "    for loc in locs:\n",
    "        loc =re.sub('<br /><br /><b',\"\",loc)\n",
    "        loc =re.sub('<br />',\"\",loc)\n",
    "        loc =re.sub('<br /><br />',\"\",loc)\n",
    "        loc =re.sub('<br',\"\",loc)\n",
    "        loc =re.sub('/>',\"\",loc)\n",
    "        \n",
    "        newlocs.append(loc)\n",
    "    return newlocs\n",
    "\n",
    "# some name need to be unified\n",
    "def drop_stop(loc):\n",
    "    new_loc = []\n",
    "    for word in loc:\n",
    "        if word not in ['The','the']:\n",
    "            new_loc.append(word.lower().rstrip('s'))\n",
    "    return new_loc\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# from collections import Counter\n",
    "# loc_description = []\n",
    "# ner_count = Counter()\n",
    "def NLP_pipeline_function(description, spacy_pipeline):\n",
    "    try:\n",
    "        ner_list = extract_ner(description, spacy_pipeline)\n",
    "        ner_list = replace_br(ner_list)\n",
    "        ner_list = drop_stop(ner_list)\n",
    "    except:\n",
    "        ner_list = []\n",
    "    return ner_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLP_processor():\n",
    "    def __init__(self):\n",
    "        self.spacy_pipeline = spacy.load(\"en_core_web_lg\")\n",
    "        self.sentence_encoder = SentenceTransformer('flax-sentence-embeddings/all_datasets_v4_MiniLM-L6')\n",
    "\n",
    "    def process_airbnb_data(self, df):\n",
    "        #### 1) NERs\n",
    "        df_ner = df[['id',\"description\"]]\n",
    "        df_ner['description'] = df_ner['description'].fillna(\"\").astype('str')\n",
    "        df_ner['ner_list'] = [NLP_pipeline_function(i, self.spacy_pipeline) for i in tqdm(df_ner['description'].values)]\n",
    "        from collections import Counter\n",
    "        all_count = Counter()\n",
    "        for l in df_ner['ner_list'].values:\n",
    "            for e in l:\n",
    "                all_count.update([e])\n",
    "        all_count_left = {k:all_count[k] for k in all_count.keys() if all_count[k]>20 and all_count[k]<1000}\n",
    "        self.NERs_left = list(all_count_left.keys()) #### store the standard NERs used\n",
    "        df_ner['ner_list_left'] = [[k for k in i if k in all_count_left.keys()] for i in df_ner['ner_list'].values]\n",
    "        df_exploded = df_ner[['id','ner_list_left']].explode('ner_list_left')\n",
    "        df_exploded['value'] = 1\n",
    "        df_exploded = df_exploded.pivot_table(index='id',columns='ner_list_left').droplevel(axis=1, level=0).fillna(0)\n",
    "\n",
    "        #### 2) Sentence embedding\n",
    "        embedded_sentences = [{f's{c}':v for c,v in enumerate(self.sentence_encoder.encode(i))} for i in tqdm(df_ner.description.values)]\n",
    "        embedded_sentences_df = pd.DataFrame(embedded_sentences)\n",
    "\n",
    "        #### final\n",
    "        final_df = []\n",
    "        for index,id in enumerate(tqdm(df['id'].values)):\n",
    "            sub = df_exploded[df_exploded.index==id].reset_index(drop=False)\n",
    "            if len(sub)==0:\n",
    "                sub = pd.DataFrame(np.array([0]* len(sub.columns)).reshape(1,-1),columns=sub.columns)\n",
    "            del sub['id']\n",
    "            final_df.append({\n",
    "                'id':id,\n",
    "                **{a:b for a,b in zip(sub.columns,list(sub.values.flatten()))},\n",
    "                **{a:b for a,b in zip(embedded_sentences_df.iloc[index,:].index, embedded_sentences_df.iloc[index,:].values)}\n",
    "            })\n",
    "        final_df = pd.DataFrame(final_df)\n",
    "        self.x_names = [i for i in list(final_df.columns) if not i=='id']\n",
    "        return final_df\n",
    "    \n",
    "    def process_new_data(self, description):\n",
    "        ner_list = NLP_pipeline_function(description, self.spacy_pipeline)\n",
    "        ner_df = {i:0 for i in self.NERs_left}\n",
    "        for i in ner_list:\n",
    "            if i in ner_df.keys():\n",
    "                ner_df[i]=1\n",
    "\n",
    "        embedded = self.sentence_encoder.encode(description)\n",
    "        embedded_df = {f's{i}':v for i,v in enumerate(list(embedded.flatten()))}\n",
    "        final_df = pd.DataFrame({\n",
    "            **ner_df,\n",
    "            **embedded_df\n",
    "        },index=[0])[self.x_names]\n",
    "        return final_df\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'../../Data/LA_Airbnb/listings_detailed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = NLP_processor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7h/dvwccw_s5f93pgp_lnn__6_40000gn/T/ipykernel_34596/2449778207.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ner['description'] = df_ner['description'].fillna(\"\").astype('str')\n",
      "100%|██████████| 40438/40438 [13:02<00:00, 51.70it/s]\n",
      "/var/folders/7h/dvwccw_s5f93pgp_lnn__6_40000gn/T/ipykernel_34596/2449778207.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ner['ner_list'] = [NLP_pipeline_function(i, self.spacy_pipeline) for i in tqdm(df_ner['description'].values)]\n",
      "100%|██████████| 40438/40438 [10:39<00:00, 63.20it/s]\n",
      "100%|██████████| 40438/40438 [01:05<00:00, 615.70it/s]\n"
     ]
    }
   ],
   "source": [
    "res = processor.process_airbnb_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.com</th>\n",
       "      <th>1 queen</th>\n",
       "      <th>101</th>\n",
       "      <th>10th &amp; wilshire</th>\n",
       "      <th>2nd street</th>\n",
       "      <th>3br/2ba</th>\n",
       "      <th>3rd street</th>\n",
       "      <th>3rd street promenade</th>\n",
       "      <th>8.5mi).</th>\n",
       "      <th>abbot kinney blvd</th>\n",
       "      <th>...</th>\n",
       "      <th>s374</th>\n",
       "      <th>s375</th>\n",
       "      <th>s376</th>\n",
       "      <th>s377</th>\n",
       "      <th>s378</th>\n",
       "      <th>s379</th>\n",
       "      <th>s380</th>\n",
       "      <th>s381</th>\n",
       "      <th>s382</th>\n",
       "      <th>s383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044766</td>\n",
       "      <td>-0.026834</td>\n",
       "      <td>-0.071107</td>\n",
       "      <td>-0.030306</td>\n",
       "      <td>-0.070291</td>\n",
       "      <td>0.060251</td>\n",
       "      <td>0.032497</td>\n",
       "      <td>0.026184</td>\n",
       "      <td>-0.060473</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 994 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   .com  1 queen  101  10th & wilshire  2nd street  3br/2ba  3rd street  \\\n",
       "0     0        0    0                1           0        0           0   \n",
       "\n",
       "   3rd street promenade  8.5mi).  abbot kinney blvd  ...      s374      s375  \\\n",
       "0                     0        0                  0  ... -0.044766 -0.026834   \n",
       "\n",
       "       s376      s377      s378      s379      s380      s381      s382  \\\n",
       "0 -0.071107 -0.030306 -0.070291  0.060251  0.032497  0.026184 -0.060473   \n",
       "\n",
       "       s383  \n",
       "0  0.019695  \n",
       "\n",
       "[1 rows x 994 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.process_new_data('this is a great palce, near to 10th & wilshire and close to 3rd street promenade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e9867b585c0f10e2eb480253e40cab44b53d9f15cdd7fb9c79b17a5cb2fa039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
