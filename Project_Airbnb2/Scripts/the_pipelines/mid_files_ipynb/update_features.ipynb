{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utiles import extract_aesthetic_features_utiles, cnn_utiles, OBJ_detection_YOLO_utiles\n",
    "from utiles.extract_aesthetic_features_utiles import get_aesthetics_one_room\n",
    "from utiles.cnn_utiles import train_loader, SimpleCNN, image_transform\n",
    "from utiles.OBJ_detection_YOLO_utiles import get_classes,parse_YOLO_result,get_listing_level_attr\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Location_pipeline import Location_processor\n",
    "from Image_pipeline import Image_processor\n",
    "from Amenity_pipeline import Amenities_processer\n",
    "from NLP_pipeline import NLP_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = pd.read_csv('../../Data/LA_Airbnb/listings_detailed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### trim price\n",
    "ori_data['price_clean'] = [float(i.strip().replace('$','').split('.')[0].replace(',','')) for i in ori_data.price]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image Features...\n",
      "done! time use: 1.409s\n"
     ]
    }
   ],
   "source": [
    "#### reading image features (not using Image_processor). **Do not** need to re-extract the features.\n",
    "time_start = datetime.datetime.now()\n",
    "print('Processing Image Features...')\n",
    "\n",
    "image_processor = Image_processor()\n",
    "image_features = pd.read_csv('./utiles/image_features.csv').rename(columns={'room_id':'id'})\n",
    "image_features = image_features.fillna(-1)\n",
    "image_features_col = list(image_features.columns)\n",
    "image_features_col = [image_features_col[0]] + [f'Image_{i}' for i in image_features_col[1:]]\n",
    "image_features.columns = image_features_col\n",
    "\n",
    "time_end = datetime.datetime.now()\n",
    "time_consumption = time_end-time_start\n",
    "print(f'done! time use: {round(time_consumption.total_seconds(), 3)}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Location Features...\n",
      "done! time use: 0.045s\n"
     ]
    }
   ],
   "source": [
    "#### reading location features. **Do not** need to re-extract the features.\n",
    "time_start = datetime.datetime.now()\n",
    "print('Processing Location Features...')\n",
    "\n",
    "import pickle\n",
    "location_processor = Location_processor()\n",
    "location_features = location_processor.process_airbnb_data(pickle.load(open('./utiles/area_features.pkl','rb')))\n",
    "\n",
    "time_end = datetime.datetime.now()\n",
    "time_consumption = time_end-time_start\n",
    "print(f'done! time use: {round(time_consumption.total_seconds(), 3)}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Amenities Features...\n",
      "done! time use: 6.493s\n"
     ]
    }
   ],
   "source": [
    "#### reading amenities features. **Need** to re-extract the features.\n",
    "#### the amenities_processor will store information like **Labelencoder**, which will be used in prediction phase\n",
    "time_start = datetime.datetime.now()\n",
    "print('Processing Amenities Features...')\n",
    "\n",
    "amenities_processor = Amenities_processer()\n",
    "amenities_features = amenities_processor.process_airbnb_data(ori_data)\n",
    "amenities_features_col = list(amenities_features.columns)\n",
    "amenities_features_col = [amenities_features_col[0]] + [f'Amenities_{i}' for i in amenities_features_col[1:]]\n",
    "amenities_features.columns = amenities_features_col\n",
    "\n",
    "time_end = datetime.datetime.now()\n",
    "time_consumption = time_end-time_start\n",
    "print(f'done! time use: {round(time_consumption.total_seconds(), 3)}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40438/40438 [13:16<00:00, 50.77it/s]\n",
      "100%|██████████| 40438/40438 [10:56<00:00, 61.59it/s]\n",
      "100%|██████████| 40438/40438 [01:05<00:00, 614.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#### reading NLP features. **Need** to re-extract the features.\n",
    "#### the nlp_processor will store information like **used NERs**, which will be used in prediction phase\n",
    "time_start = datetime.datetime.now()\n",
    "print('Processing NLP Features...')\n",
    "\n",
    "nlp_processor = NLP_processor()\n",
    "nlp_features = NLP_processor.process_airbnb_data(ori_data)\n",
    "nlp_features_col = list(nlp_features.columns)\n",
    "nlp_features_col = [nlp_features_col[0]] + [f'NLP_{i}' for i in nlp_features_col[1:]]\n",
    "nlp_features.columns = nlp_features_col\n",
    "\n",
    "time_end = datetime.datetime.now()\n",
    "time_consumption = time_end-time_start\n",
    "print(f'done! time use: {round(time_consumption.total_seconds(), 3)}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging all four part of features...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "print('Merging all four part of features...')\n",
    "all_features = ori_data[['id','price_clean']].rename(columns={'price_clean':'price'}).merge(\n",
    "    amenities_features, left_on='id',right_on='id',how='outer'\n",
    ").merge(\n",
    "    location_features, left_on='id',right_on='id',how='outer'\n",
    ").merge(\n",
    "    nlp_features, left_on='id',right_on='id',how='outer'\n",
    ").merge(\n",
    "    image_features, left_on='id',right_on='id',how='outer'\n",
    ").fillna(-1) #### some image data are missing for some listings because we failed to scrape them from the web\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m all_features\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39m./final_features/LA_extracted_all_features_imputed.csv\u001b[39m\u001b[39m'\u001b[39m,index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_features' is not defined"
     ]
    }
   ],
   "source": [
    "all_features.to_csv('./final_features/LA_extracted_all_features_imputed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb Cell 11\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./saved_pipelines/image_processor.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(image_processor, f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m./saved_pipelines/location_processor.pkl\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chenyangkang/Desktop/MADS/699/Project/Project_Airbnb2/Scripts/the_pipelines/update_features.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     pickle\u001b[39m.\u001b[39mdump(location_processor, f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_processor' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('./saved_pipelines/image_processor.pkl','wb') as f:\n",
    "    pickle.dump(image_processor, f)\n",
    "\n",
    "with open('./saved_pipelines/location_processor.pkl','wb') as f:\n",
    "    pickle.dump(location_processor, f)\n",
    "\n",
    "with open('./saved_pipelines/amenities_processor.pkl','wb') as f:\n",
    "    pickle.dump(amenities_processor, f)\n",
    "\n",
    "with open('./saved_pipelines/nlp_processor.pkl','wb') as f:\n",
    "    pickle.dump(nlp_processor, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e9867b585c0f10e2eb480253e40cab44b53d9f15cdd7fb9c79b17a5cb2fa039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
